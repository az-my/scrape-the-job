name: Manual Web Scraping

on:
  schedule:
    - cron: '1 0 * * *'  # This schedules the workflow at 00:01 AM (midnight)

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Check Out Repository
        uses: actions/checkout@v2

      - name: Set Up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.x'

      - name: Install Dependencies
        run: |
          pip install requests beautifulsoup4 pandas

      - name: Run Web Scraping Script
        run: |
          python js.py

      - name: Generate JSON and CSV
        run: |
          mkdir -p data
          python js.py
          # Force replace (overwrite) the files if they exist
          cp -f job_data.json $GITHUB_WORKSPACE/data/job_data.json
          cp -f job_data.csv $GITHUB_WORKSPACE/data/job_data.csv

      - name: Commit and Push Changes
        run: |
          git config user.name "GitHub Actions"
          git config user.email "<actions@users.noreply.github.com>"
          git add data/job_data.json data/job_data.csv
          git commit -m "Auto-generate JSON and CSV files"
          git push https://${{ secrets.PAT_TOKEN }}@github.com/az-my/scrape-the-job.git
